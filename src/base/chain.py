from langchain import LLMChain, PromptTemplatefrom langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplatefrom langchain.chat_models import ChatLiteLLMfrom src.base.utils import extract_prompt_placeholders, trans_messages_2_str, trans_str_2_messages_formclass LLMChainModule(LLMChain):    """    Represents an executable module centered around abstract prompt words, capable of accepting     input for placeholders to generate prompts that can be executed by a large language model.    Attributes:        input_variables (list): A list of placeholder names used in the current prompt words.    Raises:        KeyError: If 'input_variables' is not provided in kwargs.    """    def get_input_variables(self):        """        return the placeholders of the prompt        Returns: the placeholders of the prompt        """        return self.prompt.input_variables    def get_original_prompt(self):        """        return the original prompt content        Returns: the original prompt content        """        return self.prompt.template    async def get_composed_prompt(self, **kwargs):        """        Asynchronously generates the corresponding prompt content when the current module is        executed, based on the values provided for each placeholder.        Args:            **kwargs: The values corresponding to each placeholder in the prompt when the large             language model is running.        Returns:            The generated prompt word content as a string.        """        inputs = self.prep_inputs(kwargs)        prompts, stop = await self.aprep_prompts([inputs])        if hasattr(prompts[0], 'text'):            return prompts[0].text        else:            return trans_messages_2_str(messages=prompts[0].messages[0].content)    @classmethod    def from_llm(cls, llm: ChatLiteLLM, prompt: str, verbose: bool = True) -> 'LLMChainModule':        """        Class method that constructs and returns an instance of LLMChainModule using the        provided prompt word.        Args:            llm (ChatLiteLLM): The large language model instance.            prompt (str): The prompt word used to construct the instance.            verbose (bool): Execution mode, verbose by default.        Returns:            An instance of LLMChainModule.        """        input_variables = extract_prompt_placeholders(prompt)        image_values = list(set([v for v in input_variables if v.split(":")[-1] == 'image']))        if len(image_values) > 0:            # Split prompt and refactor it into list type            prompt_message = trans_str_2_messages_form(prompt=prompt,                                                       image_values=["{" + v + "}" for v in image_values])            prompt = ChatPromptTemplate.from_messages([                HumanMessagePromptTemplate.from_template(prompt_message)            ])        else:            # Normal Mode            prompt = PromptTemplate(template=prompt, input_variables=input_variables)        return cls(prompt=prompt, llm=llm, verbose=verbose)