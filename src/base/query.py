import requestsimport randomimport uuidimport timefrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.embeddings import HuggingFaceEmbeddingsfrom src.config import AZURE_OPENAI_API_KEYfrom src.config import AZURE_OPENAI_API_BASEfrom src.config import EMBEDDING_MODEL_NAMEfrom src.config import EMBEDDING_MODEL_TYPEfrom src.config import VEARCH_CONFIGfrom src.base.utils import then_call_process_query_resultsfrom src.base.utils import async_then_call_process_query_resultsfrom abc import ABC, abstractmethod, ABCMetafrom typing import Anyfrom src.base.utils import add_call_async_func_2_logfrom src.base.utils import add_call_func_2_logclass _DecorateAllMethods(type):    """A metaclass that decorates all methods of a subclass.    This metaclass iterates over all attributes of a class being created. If an attribute is a callable    (i.e., a method), it checks if the method is overriding a method from its base classes. If it is,    and if the method name matches specific criteria, it applies a decorator to the method. This approach    ensures that methods overriding abstract methods still retain the intended decorators from the superclass.    """    def __new__(mcs, name, bases, dct):        # Iterate over all attributes of the class        for attr, value in dct.items():            # Check if the attribute is a callable (i.e., likely a method)            if callable(value):                is_over_write = False                # Check if this method overrides a method from its base classes                for base in bases:                    if hasattr(base, attr) and getattr(base, attr) is not value:                        is_over_write = True                        break                # Apply specific decorators based on the method's name and whether it overrides a base class method                if attr == 'process_query_results':                    dct[attr] = add_call_func_2_log(value)        # Create the new class with the possibly modified dictionary of attributes/methods        return super().__new__(mcs, name, bases, dct)class _CombinedMeta(ABCMeta, _DecorateAllMethods):    """    In order to avoid conflicts caused by other classes inherited by the class that are    not of the same origin as the primitive class, the primitive class and abstract class    ABCMeta are merged to avoid conflicts.    """    pass# Fetches the cluster statistics from the given master URL.def get_cluster_stats(master_url):    url = f"{master_url}/_cluster/stats"  # URL for cluster statistics endpoint    resp = requests.get(url)  # Sends a GET request to the endpoint    return resp.json()  # Returns the JSON response# Fetches the cluster health status from the given master URL.def get_cluster_health(master_url):    url = f"{master_url}/_cluster/health"  # URL for cluster health endpoint    resp = requests.get(url)  # Sends a GET request to the endpoint    return resp.json()  # Returns the JSON response# Fetches the status of all servers from the given master URL.def get_servers_status(master_url):    url = f"{master_url}/list/server"  # URL for server status endpoint    resp = requests.get(url)  # Sends a GET request to the endpoint    return resp.json()  # Returns the JSON response# Lists all databases from the given master URL.def list_dbs(master_url):    url = f"{master_url}/list/db"  # URL for listing databases endpoint    resp = requests.get(url)  # Sends a GET request to the endpoint    return resp.json()  # Returns the JSON response# Creates a new database with the given name.def create_db(master_url, db_name):    url = f"{master_url}/db/_create"  # URL for creating a database endpoint    data = {"name": db_name}  # Data payload for the request    resp = requests.put(url, json=data)  # Sends a PUT request with the payload    return resp.json()  # Returns the JSON response# Fetches information for a specific database.def get_db(master_url, db_name):    url = f"{master_url}/db/{db_name}"  # URL for specific database endpoint    resp = requests.get(url)  # Sends a GET request to the endpoint    return resp.json()  # Returns the JSON response# Drops a specific database.def drop_db(master_url, db_name):    url = f"{master_url}/db/{db_name}"  # URL for dropping a database endpoint    resp = requests.delete(url)  # Sends a DELETE request to the endpoint    return resp.text  # Returns the response text# Lists all spaces for a given database.def list_spaces(master_url, db_name):    url = f"{master_url}/list/space?db={db_name}"  # URL for listing spaces endpoint    resp = requests.get(url)  # Sends a GET request to the endpoint    return resp.json()  # Returns the JSON response# Creates a new space with the provided configuration.def create_space(master_url, db_name, space_config):    url = f"{master_url}/space/{db_name}/_create"  # URL for creating a space endpoint    resp = requests.put(url, json=space_config)  # Sends a PUT request with the configuration    return resp.json()  # Returns the JSON response# Fetches information for a specific space.def get_space(master_url, db_name, space_name):    url = f"{master_url}/space/{db_name}/{space_name}"  # URL for specific space endpoint    resp = requests.get(url)  # Sends a GET request to the endpoint    return resp.json()  # Returns the JSON response# Drops a specific space.def drop_space(master_url, db_name, space_name):    url = f"{master_url}/space/{db_name}/{space_name}"  # URL for dropping a space endpoint    resp = requests.delete(url)  # Sends a DELETE request to the endpoint    return resp.text  # Returns the response text# Inserts a single document into the specified space.def insert_one(router_url, db_name, space_name, data, doc_id=None):    # Constructs the URL for inserting a document, with or without a specified ID    if doc_id:        url = f"{router_url}/{db_name}/{space_name}/{doc_id}"    else:        url = f"{router_url}/{db_name}/{space_name}"    resp = requests.post(url, json=data)  # Sends a POST request with the document data    return resp.json()  # Returns the JSON response# Inserts multiple documents in a single batch.def insert_batch(router_url, db_name, space_name, data_list):    url = f"{router_url}/{db_name}/{space_name}/_bulk"  # URL for bulk insert endpoint    resp = requests.post(url, data=data_list)  # Sends a POST request with the list of documents    return resp.text  # Returns the response text# Updates a specific document with the given ID.def update(router_url, db_name, space_name, data, doc_id):    url = f"{router_url}/{db_name}/{space_name}/{doc_id}/_update"  # URL for update endpoint    resp = requests.post(url, json=data)  # Sends a POST request with the updated data    return resp.text  # Returns the response text# Deletes a specific document with the given ID.def delete(router_url, db_name, space_name, doc_id):    url = f"{router_url}/{db_name}/{space_name}/{doc_id}"  # URL for delete endpoint    resp = requests.delete(url)  # Sends a DELETE request to the endpoint    return resp.text  # Returns the response text# Searches for documents in the given space.def search(router_url, db_name, space_name, query):    url = f"{router_url}/{db_name}/{space_name}/_search"  # URL for search endpoint    resp = requests.post(url, json=query)  # Sends a POST request with the search query    return resp.json()  # Returns the JSON response# Fetches a specific document by its ID.def get_by_id(router_url, db_name, space_name, doc_id):    url = f"{router_url}/{db_name}/{space_name}/{doc_id}"  # URL for fetching a document by ID    resp = requests.get(url)  # Sends a GET request to the endpoint    return resp.json()  # Returns the JSON response# Fetches multiple documents by their IDs.def mget_by_ids(router_url, db_name, space_name, query):    url = f"{router_url}/{db_name}/{space_name}/_query_byids"  # URL for multi-get by IDs    resp = requests.post(url, json=query)  # Sends a POST request with the list of IDs    return resp.json()  # Returns the JSON response# Conducts bulk searches for multiple queries.def bulk_search(router_url, db_name, space_name, queries):    url = f"{router_url}/{db_name}/{space_name}/_bulk_search"  # URL for bulk search endpoint    resp = requests.post(url, json=queries)  # Sends a POST request with the queries    return resp.json()  # Returns the JSON response# Conducts a multi-search for different queries.def msearch(router_url, db_name, space_name, query):    url = f"{router_url}/{db_name}/{space_name}/_msearch"  # URL for multi-search endpoint    resp = requests.post(url, json=query)  # Sends a POST request with the query    return resp.json()  # Returns the JSON response# Searches by ID with a feature query.def search_by_id_feature(router_url, db_name, space_name, query):    url = f"{router_url}/{db_name}/{space_name}/_query_byids_feature"  # URL for feature search by IDs    resp = requests.post(url, json=query)  # Sends a POST request with the query    return resp.json()  # Returns the JSON response# Deletes documents based on a query.def delete_by_query(router_url, db_name, space_name, query):    url = f"{router_url}/{db_name}/{space_name}/_delete_by_query"  # URL for delete by query endpoint    resp = requests.post(url, json=query)  # Sends a POST request with the query    return resp.text  # Returns the response textclass _Embedding:    """    embedding模块        通过配置选择embedding模型;        embed_documents, 支持batch防止(chatgpt)调用接口报错;        embed_query    """    def __init__(self,                 embedding_model_name,                 openai_api_key,                 openai_api_base,                 model,                 chunk_size,                 max_retries):        self.model_name = model        self.open_api_key = openai_api_key        self.embedding_model = self.get_embedding_model(            embedding_model_name,            openai_api_key,            openai_api_base,            model,            chunk_size,            max_retries        )        # embed 接口调用的retry次数        self.max_retry = 20    @staticmethod    def get_embedding_model(model_name,                            openai_api_key,                            openai_api_base,                            model,                            chunk_size,                            max_retries):        """        选择 embedding model        """        kwargs = {'openai_api_key': openai_api_key,                  'openai_api_base': openai_api_base,                  'model': model,                  'chunk_size': chunk_size,                  'max_retries': max_retries}        if model_name == "OpenAIEmbeddings":            return OpenAIEmbeddings(**kwargs)        elif model_name == "HuggingFaceEmbeddings":            return HuggingFaceEmbeddings(**kwargs)        else:            return None    def embed_documents(self, texts, batch_size=None):        """        批量 embedding        Args:            texts (list of str): 文本            batch_size (_type_, optional): 设置调用batch_size, 防止调用接口报错. Defaults to None.        """        if batch_size is None:            # 设置默认batch_size            batch_size = len(texts)        embeddings = []        retry = self.max_retry        for start in range(0, len(texts), batch_size):            while retry > 0:                # 尝试 max_retry 次, 如不成功放弃治疗                try:                    embeddings.extend(                        self.embedding_model.embed_documents(                            texts[start: start + batch_size]                        )                    )                    retry = self.max_retry                    break                except Exception as e:                    time.sleep(1)                    retry -= 1                    print(f"retry embed_documents, {e} 倒数第 {retry} 次尝试")        assert len(embeddings) == len(texts), "embed_documents 失败"        return embeddings    def embed_query(self, text, retry=20):        """        单条embedding        加入retry        """        embedding = []        retry = self.max_retry        while retry > 0:            # 尝试 max_retry 次, 如不成功放弃治疗            try:                embedding = self.embedding_model.embed_query(text)                break            except Exception as e:                time.sleep(1)                retry -= 1                print(f"retry embed_query,{e}  倒数第 {retry} 次尝试")        assert embedding != [], "embed_query失败"        return embedding    def http_embed_query(self, text: str, retry_times=20):        retry = retry_times        while retry > 0:            # 尝试 max_retry 次, 如不成功放弃治疗            try:                model_key = "2f8aea96-35aa-47f4-8efe-01266b36c762"                model_name = "text-embedding-ada-002-2"                response = requests.post(                    url="http://gpt-proxy.jd.com/gateway/azure" + "/embeddings",                    json={"model": self.model_name, "erp": "", "prompt": text},                    headers={                        "Content-Type": "application/json",                        "Authorization": f"Bearer {self.open_api_key}",                    },                )                # print(response.json())                embedding = response.json()["data"][0]["embedding"]                retry = retry_times                # break                return embedding            except Exception as e:                time.sleep(1)                retry -= 1                print(f"retry embedding, {e} 倒数第 {retry} 次尝试")        return Noneclass _Vearch:    """    A class dedicated to handling operations related to the Vearch database. Vearch is a distributed system optimized    for vector search and storage. This class encapsulates functionalities such as creating and querying spaces    within the Vearch database.    Vearch spaces are analogous to tables in traditional relational databases but are designed to handle vectorized    data efficiently. This class provides an interface for interacting with these spaces, enabling operations like    space creation, modification, and deletion, as well as inserting and querying vector data.    Note:        This class is prefixed with an underscore (_) to denote its intended use as a private or internal class        within a module or package. It may not be designed for direct use in external code.    Attributes:        master_url (str): The URL of the master node in the Vearch cluster. This node is responsible for metadata            management and cluster coordination.        router_url (str): The URL of the router node in the Vearch cluster. This node handles query routing and            load balancing across different partitions.        db_name (str): The name of the database within the Vearch cluster that this class instance will interact with.        space_name (str): The name of the space within the database to which operations will be directed.        embedding_dimension (int, optional): The dimensionality of the embedding vectors that the space is expected            to handle. This is relevant for spaces that store vector data.    Example:        To use this class, instantiate it with the necessary configuration for your Vearch database and then call        its methods to perform operations on spaces:        ```python        vearch_client = _Vearch(master_url="http://example.com", router_url="http://example.com",                                db_name="mydatabase", space_name="myspace")        vearch_client.create_space(space_config)        ```    """    def __init__(self, *args, **kwargs):        """        Initializes a new instance of the class, setting up the necessary configuration for interacting with a Vearch        database. Vearch is a database system designed for vectorized data and search operations.        The configuration should specify the URLs for the master and router nodes of the Vearch cluster, as well as the        database and space names that this instance will interact with. Additionally, the configuration may include        the dimension of the embeddings that the space will store, if applicable.        Args:            *args: Variable length argument list. Expected to receive the master_url, router_url, db_name, and                space_name in that order if kwargs are not provided.            **kwargs: Arbitrary keyword arguments. The following keys are expected in the kwargs dictionary:                - master_url (str): The URL of the master node in the Vearch cluster.                - router_url (str): The URL of the router node in the Vearch cluster.                - db_name (str): The name of the database within the Vearch cluster.                - space_name (str): The name of the space within the database to which operations will be directed.                - embedding_dimension (int, optional): The dimensionality of the embedding vectors that the space will                  handle. This is an optional configuration and is specific to spaces that store vector data.        Note:            The method uses `kwargs.get` with a default fallback to the positional arguments (`args`). This allows for            both named and positional argument passing styles. If both `args` and `kwargs` are provided, `kwargs` will            take precedence.        """        # Set the master, router URLs, and the database and space names using kwargs with fallback to args.        self.master_url = kwargs.get('master_url', args[0] if len(args) > 0 else None)        self.router_url = kwargs.get('router_url', args[1] if len(args) > 1 else None)        self.db_name = kwargs.get('db_name', args[2] if len(args) > 2 else None)        self.space_name = kwargs.get('space_name', args[3] if len(args) > 3 else None)    def create_space(self, space_config: dict):        """        Creates a new space within the knowledge database according to the provided configuration. A space is akin        to a table in traditional relational databases, serving as a container for documents that share a common        schema and configuration.        Args:            space_config (dict): A dictionary containing the configuration settings for the new space. This can include                settings such as the space's schema, indexing preferences, and other relevant configurations specific                to how the space should be structured and managed within the database.        Returns:            The result of the space creation operation. The exact format of the return value depends on the            implementation of the `create_space` function and the database's response to the creation request.            Typically, this could include a success message, the ID of the created space, or details of any errors            encountered during the creation process.        Note:            The method delegates the actual creation of the space to the `create_space` function, which requires the            URL of the master node of the database cluster, the name of the database, and the space configuration            dictionary. Future implementations may consider extracting the space configuration to an external            configuration file for easier management and modification.        """        # Create a new space in the database with the provided configuration and return the result        return create_space(self.master_url, self.db_name, space_config)    def get_space(self):        """        Retrieves the metadata and configuration details of a specific space within the knowledge database. A space        is a logical partition within the database, similar to a table in a relational database system, which holds        the documents.        Returns:            The metadata and configuration information of the space within the knowledge database. The return format            is dependent on the implementation of the `get_space` function and the specific database management system            in use. Typically, this information includes details such as the space's schema, indexing settings, and            other relevant configurations.        Note:            The `get_space` function is an abstraction for fetching space details from the database. It requires the            URL of the master node of the database cluster, the name of the database, and the name of the space.        """        # Fetch and return the details of the specified space from the database        return get_space(self.master_url, self.db_name, self.space_name)    def add_document(self, **kwargs):        """        Adds a single document to the knowledge database. The document's content is specified by the keyword arguments        provided. Each key-value pair in the keyword arguments represents a field and its content for the document.        Args:            **kwargs: Variable length keyword arguments. Each key-value pair corresponds to a field name and the data                to be stored in that field for the document being inserted into the database.        Returns:            The result of the document insertion operation. The exact format of the return value depends on the            implementation of the `insert_one` function and the database's response upon insertion.        Note:            The method generates a unique identifier (UUID) for the new document, ensuring that each document added            to the database has a unique ID. The UUID is stripped of hyphens before being used as the document ID.            The `insert_one` function is an abstraction that handles the actual insertion of the document into the            database. It requires the URL of the router node, the database name, the space name (similar to a table            in relational databases), the document data, and the document ID.        """        # Prepare the document data with the provided keyword arguments        data = kwargs        # Generate a unique document identifier (UUID) and remove hyphens        data_uuid = str(uuid.uuid4()).replace("-", "")        # Insert the document into the database and return the result of the insertion        return insert_one(            self.router_url, self.db_name, self.space_name, data, doc_id=data_uuid        )    def search_document(self, embedding, query_field, top_k=1, min_score: float = None):        """        Searches for documents in the knowledge database that are similar to the provided embedding. The search is        performed within a specified field of the database documents. Results are filtered based on a minimum similarity        score, if provided, and a specified number of top results to return.        Args:            embedding: The vector representation of the query or document for which similar documents are to be found.                This embedding should match the dimensionality and format expected by the database's similarity search                functionality.            query_field: The name of the field within the database documents against which the similarity of the            embedding                will be calculated. This determines which part of the document is considered for similarity comparison.            top_k (int, optional): The maximum number of similar documents to return, ranked by their similarity to the                embedding. Defaults to 1, meaning only the most similar document is returned.            min_score (float, optional): A threshold for the similarity score. Only documents with a similarity score                higher than this value will be returned. This parameter allows filtering of the results to ensure a                minimum level of relevance. Must be a value between 0 and 1, inclusive.        Returns:            The search results containing the documents that match the query criteria. The exact format of the return            value depends on the implementation of the `search` function and the structure of the database documents.        Raises:            ValueError: If the `min_score` is provided but is not within the range (0, 1), indicating an invalid                threshold for similarity scores.        Note:            The method constructs a query that is sent to the database through a search interface, which is abstracted            here by the `search` function. This abstraction allows for flexibility in how the search is implemented and            the specific database or search engine used.        """        # Validate the min_score parameter if provided        if min_score is not None and (min_score < 0 or min_score > 1):            raise ValueError("The value of min_score must be inside (0,1)")        # Construct the base query structure        query = {            "query": {                "sum": [                    {                        "field": query_field,                        "feature": embedding,                    }                ],            },            "is_brute_search": 1,            "size": top_k,        }        # If min_score is provided, add it to the query        if min_score is not None:            query["query"]["sum"][0]["min_score"] = min_score        # Execute the search using the constructed query and return the results        return search(self.router_url, self.db_name, self.space_name, query)class QueryModule(ABC, metaclass=_CombinedMeta):    """    Initializes an instance of the knowledge base class designed for querying a database. This class is tailored        for applications like FastChatAPP that require querying services from a database but do not support operations        for data insertion into the database. It sets up the necessary configurations for interacting with the database        and for embedding query contents using a specified model.    """    def __init__(self,                 openai_api_key=None,                 embed_type=EMBEDDING_MODEL_TYPE,                 embed_model=EMBEDDING_MODEL_NAME,                 chunk_size=1,                 max_retries=6,                 master_url=VEARCH_CONFIG.get('master_url', ''),                 router_url=VEARCH_CONFIG.get('router_url', ''),                 db_name=VEARCH_CONFIG.get('db_name', ''),                 space_name=VEARCH_CONFIG.get('space_name', '')):        """        Initializes an instance of the knowledge base class designed for querying a database. This class is tailored        for applications like FastChatAPP that require querying services from a database but do not support operations        for data insertion into the database. It sets up the necessary configurations for interacting with the database        and for embedding query contents using a specified model.        Args:            openai_api_key (str): The API key used for authentication with the gateway. This key is essential for                accessing the embedding services provided by OpenAI, selected randomly from a list of available API                keys.            embed_model (str): The name of the embedding model to be used for generating embeddings from query contents.                This model is used to transform text queries into vector representations for database searching.            chunk_size (int): A core parameter that specifies the chunk size used by the embedding model. This parameter                can affect the performance and the quality of the embeddings generated.            max_retries (int): The maximum number of retries for embedding generation in case of failures or errors                during the embedding process.            master_url (str): A core parameter indicating the URL of the master node of the database. This URL is used                for administrative operations on the database.            router_url (str): A core parameter indicating the URL of the router node of the database. This URL is used                for query routing within the database infrastructure.            db_name (str): The name of the database to be queried. This specifies which database within the system                the queries should be directed to.            space_name (str): The name of the space within the database where the data resides. In the context of                databases like Vearch, a space is analogous to a table in relational databases.        Note:            This constructor assumes the presence of global configurations such as `AZURE_OPENAI_API_KEYS`,            `EMBEDDING_MODEL_NAME`, and `VEARCH_CONFIG` which contain the necessary settings and credentials for            accessing the embedding services and the database. The actual implementation of the database interaction            (`_Vearch`) and embedding services (`OpenAIEmbeddings`) are abstracted from this method.        """        if openai_api_key is not None:            self.embedding_model = _Embedding(embedding_model_name=embed_type,                                              openai_api_key=openai_api_key,                                              openai_api_base=AZURE_OPENAI_API_BASE,                                              model=embed_model,                                              chunk_size=chunk_size,                                              max_retries=max_retries)        else:            self.embed_type = embed_type            self.openai_api_base = AZURE_OPENAI_API_BASE            self.model = embed_model            self.chunk_size = chunk_size            self.max_retries = max_retries            self.embedding_class = _Embedding        self.knowledge_database = _Vearch(master_url=master_url,                                          router_url=router_url,                                          db_name=db_name,                                          space_name=space_name)    @async_then_call_process_query_results    @add_call_async_func_2_log    async def async_query(self,                          query_content: str,                          query_field: str,                          top_k: int,                          result_fields: list,                          min_score: float = None):        """        异步执行查询知识库，并获取到相应的查询结果。        Args:            query_content: 查询内容            query_field: 查询向量知识库的字段            top_k: 返回的最相关的数据量            result_fields: 返回的结果字段            min_score: 最小得分        Returns:        """        if hasattr(self, 'is_disable') and getattr(self, 'is_disable'):            setattr(self, 'is_disable', False)            return None        text_embedding = self.embedding_model.embed_query(query_content)        res = self.knowledge_database.search_document(embedding=text_embedding,                                                      query_field=query_field,                                                      top_k=top_k,                                                      min_score=min_score)        if len(res.get('error', {})) > 0:            raise ValueError(f"Something wrong happens while querying because {res.get('error').get('reason')}.")        results = []        if len(res['hits'].get('hits', [])) > 0:            for ele in res['hits']['hits']:                result = {result_field: ele['_source'][result_field] for result_field in result_fields}                results.append(result)        return query_content, results    @then_call_process_query_results    @add_call_func_2_log    def query(self,              query_content: str,              query_field: str,              top_k: int,              result_fields: list,              min_score: float = None):        """        Executes a search in the knowledge base for entries related to the topic of `query_content`. This method        leverages an embedding model to convert the query content into an embedding and uses this embedding to search        the knowledge database. The search is performed on a specific field of the database entries, as determined by        `query_field`. The method returns the top `top_k` entries that are most relevant to the query content,        optionally filtering results to only include those with a relevance score above `min_score`.        Args:            result_fields: The query result fields.            query_content (str): The query string that describes the topic of interest.            query_field (str): The field within the knowledge base documents against which the query content's                               similarity is calculated. This field is used to find the most relevant documents.            top_k (int): The number of top relevant knowledge entries to return.            min_score (float, optional): The minimum score threshold for relevance. Only documents with a relevance            score higher than this value are included in the results. If not specified, no minimum score filtering is            applied.        Returns:            list of dict: A list of dictionaries, each representing a knowledge entry. Each dictionary contains the            title and content of the entry, corresponding to the most relevant entries found in the knowledge base.            The number of entries returned is up to `top_k`, and each entry's relevance score is above `min_score` if            it is specified.        Note:            This method assumes that an embedding model (`self.embedding_model`) and a knowledge database            (`self.knowledge_database`) are available within the class instance. The embedding model is used to convert            the query content into an embedding vector, and the knowledge database is queried with this vector to find            relevant documents.        """        if hasattr(self, 'is_disable') and getattr(self, 'is_disable'):            setattr(self, 'is_disable', False)            return None        text_embedding = self.embedding_model.http_embed_query(query_content)        res = self.knowledge_database.search_document(embedding=text_embedding,                                                      query_field=query_field,                                                      top_k=top_k,                                                      min_score=min_score)        results = []        for ele in res['hits']['hits']:            result = {result_field: ele['_source'][result_field] for result_field in result_fields}            results.append(result)        return query_content, results    @abstractmethod    def process_query_results(self, query_content: str, query_results: list) -> Any:        """        Processes the results obtained from a query. The results processed by this function will be returned        to the 'process_query_results' method in the ChatApplication class. It is imperative to coordinate        the interaction interface with the developers of the ChatApplication class.        This is an abstract method, meaning that it must be implemented by any subclass that inherits from the class        containing this method. The purpose of this method is to allow for flexibility in how query results are        processed,        depending on the specific needs of the subclass.        Args:            query_content (str): The content of the query made to the knowledge base.            query_results (list): The results returned from the knowledge base query.        Returns:            Any: The processed results, which will be in a format suitable for further use or display. The exact            type and structure of the return value will depend on the implementation in the subclass.        Note:            This method is an abstract method and must be overridden in the subclass. It does not contain any            implementation in this form and will raise a TypeError if an attempt is made to instantiate the class            without overriding this method in a subclass.        """        pass